{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf42cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "from keras.models import Sequential\n",
    "from pymongo import MongoClient\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "class MongoDatabase:\n",
    "    def __init__(self):\n",
    "        CONNECTION_STRING = \"\"\n",
    "        self.client = MongoClient(CONNECTION_STRING)\n",
    "\n",
    "    def _fetch_data(self, collection_name, limit=None):\n",
    "        try:\n",
    "            collection = self.client[\"TestAPI\"][collection_name]\n",
    "            cursor = collection.find({}).limit(limit) if limit else collection.find({})\n",
    "            return pd.DataFrame(list(cursor))\n",
    "        except Exception as e:\n",
    "            print(f\"Error while fetching data from {collection_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_environment(self, limit=None):\n",
    "        return self._fetch_data(\"\", limit)\n",
    "\n",
    "    def get_growth(self, limit=None):\n",
    "        return self._fetch_data(\"\", limit)\n",
    "    \n",
    "def create_dataset(X, y, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        sequence = X[i:(i + look_back), :]\n",
    "        dataX.append(sequence)\n",
    "        output = y[i + look_back]\n",
    "        dataY.append(output)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "db = MongoDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "from keras.models import Sequential\n",
    "from pymongo import MongoClient\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "class MongoDatabase:\n",
    "    def __init__(self):\n",
    "        CONNECTION_STRING = \"mongodb://netdb:netdb3230!@10.255.93.173:27017/\"\n",
    "        self.client = MongoClient(CONNECTION_STRING)\n",
    "\n",
    "    def _fetch_data(self, collection_name, limit=None):\n",
    "        try:\n",
    "            collection = self.client[\"TestAPI\"][collection_name]\n",
    "            cursor = collection.find({}).limit(limit) if limit else collection.find({})\n",
    "            return pd.DataFrame(list(cursor))\n",
    "        except Exception as e:\n",
    "            print(f\"Error while fetching data from {collection_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_environment(self, limit=None):\n",
    "        return self._fetch_data(\"GH1\", limit)\n",
    "\n",
    "    def get_growth(self, limit=None):\n",
    "        return self._fetch_data(\"hydroponics_length1\", limit)\n",
    "    \n",
    "def create_dataset(X, y, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        sequence = X[i:(i + look_back), :]\n",
    "        dataX.append(sequence)\n",
    "        output = y[i + look_back]\n",
    "        dataY.append(output)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "db = MongoDatabase()\n",
    "\n",
    "# Y data\n",
    "growth_data_1 = db.get_growth()\n",
    "growth_data_2 = growth_data_1[['growth length   (cm)']]\n",
    "\n",
    "# X data\n",
    "environment_data_1 = db.get_environment(limit = 31200)\n",
    "environment_data_2 = environment_data_1[['temp', 'humidity']]\n",
    "environment_averaged = environment_data_2.groupby(environment_data_2.index // 100).mean(numeric_only=True).reset_index(drop=True)\n",
    "\n",
    "# X+Y\n",
    "training_data = pd.merge(environment_averaged, growth_data_2, left_index=True, right_index=True)\n",
    "\n",
    "# split train, test\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(training_data)\n",
    "X_data = data_normalized[:, :-1]\n",
    "y_data = data_normalized[:, -1]\n",
    "look_back = 24\n",
    "X, Y = create_dataset(X_data, y_data, look_back)\n",
    "\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, shuffle=False)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "def create_lstm_model(units = 64,\n",
    "                    activation='relu',\n",
    "                    recurrent_activation='sigmoid',\n",
    "                    use_bias = True,\n",
    "                    kernel_initializer= 'glorot_uniform',\n",
    "                    recurrent_initializer = 'orthogonal',\n",
    "                    bias_initializer = 'zeros',\n",
    "                    unit_forget_bias = True,\n",
    "                    kernel_regularizer = None,\n",
    "                    recurrent_regularizer=None,\n",
    "                    bias_regularizer=None,\n",
    "                    activity_regularizer = None,\n",
    "                    kernel_constraint = None,\n",
    "                    recurrent_constraint = None,\n",
    "                    bias_constraint = None,\n",
    "                    dropout = 0.0,\n",
    "                    recurrent_dropout = 0.0,\n",
    "                    return_sequences = False,\n",
    "                    return_state = False,\n",
    "                    go_backwards = False,\n",
    "                    stateful = None,\n",
    "                    unroll = None):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(\n",
    "                    units=units,\n",
    "                    activation= activation, \n",
    "                    recurrent_activation = recurrent_activation,\n",
    "                    use_bias = use_bias,\n",
    "                    kernel_initializer = kernel_initializer,\n",
    "                    recurrent_initializer = recurrent_initializer,\n",
    "                    bias_initializer = bias_initializer,\n",
    "                    unit_forget_bias =  unit_forget_bias,\n",
    "                    kernel_regularizer = kernel_regularizer,\n",
    "                    recurrent_regularizer = recurrent_regularizer,\n",
    "                    bias_regularizer = bias_regularizer,\n",
    "                    activity_regularizer = activity_regularizer,\n",
    "                    kernel_constraint = kernel_constraint,\n",
    "                    recurrent_constraint = recurrent_constraint,\n",
    "                    bias_constraint = bias_constraint,\n",
    "                    dropout = dropout,\n",
    "                    recurrent_dropout = recurrent_dropout,\n",
    "                    return_sequences = return_sequences,\n",
    "                    return_state = return_state,\n",
    "                    go_backwards = go_backwards,\n",
    "                    stateful = stateful,\n",
    "                    unroll = unroll, \n",
    "                    input_shape=(look_back, 2)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss = 'mean_squared_error',\n",
    "        metrics = [\n",
    "            keras.metrics.MeanSquaredError(),\n",
    "            keras.metrics.RootMeanSquaredError(),\n",
    "            keras.metrics.MeanAbsoluteError()\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "lstm_regressor = KerasRegressor(build_fn=create_lstm_model, verbose = 0)\n",
    "\n",
    "param_grid = {\n",
    "    'units' : [64, 128], \n",
    "    'epochs': [10],\n",
    "    'batch_size': [32, 64],\n",
    "    'activation': ['sigmoid'],\n",
    "    'recurrent_activation': ['sigmoid'],\n",
    "    'dropout' : [0.1, 0.4], \n",
    "    'recurrent_dropout': [0.0, 0.1] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lstm_regressor, param_grid=param_grid)\n",
    "grid_result = grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "results = pd.DataFrame(grid_result.cv_results_)\n",
    "top_10_results = results.nlargest(10, 'mean_test_score')\n",
    "\n",
    "print(top_10_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
